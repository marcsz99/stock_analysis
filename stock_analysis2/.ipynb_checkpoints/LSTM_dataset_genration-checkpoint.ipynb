{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f8b976d-d90a-4d9f-a205-1ad96de37c94",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/Users/marcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9db7b865-3780-4411-a767-1643181d366c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pickle_loader import pickle_loader\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d82b98-847e-4315-854f-b005ea5c1ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "technical_data = pickle_loader('/Users/marcs/OneDrive/Documents/stock_analysis2/technical_us.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d545311-611b-4f5e-bae0-dd743783c72c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Remove Tickers that don't contain the full dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeaf5fca-130d-488d-ab08-b9234cfb48e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tech_clean(dataset):\n",
    "    clean_dataset = dataset.copy()\n",
    "    tickers = list(technical_data.keys())\n",
    "    removed_tickers = []\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        if len(dataset[ticker]) == 0: # Remove tickers that are empty \n",
    "            clean_dataset.pop(ticker, None)\n",
    "            removed_tickers.append(ticker)\n",
    "        else: # Remove tickers that don't contain the full dataset \n",
    "            first_time = dataset[ticker].index.to_pydatetime()[0].strftime('%d-%m-%Y')\n",
    "            last_time = dataset[ticker].index.to_pydatetime()[-1].strftime('%d-%m-%Y')\n",
    "            if first_time != '30-09-2021' or last_time != '29-09-2023':\n",
    "                clean_dataset.pop(ticker, None)\n",
    "                removed_tickers.append(ticker)\n",
    "    \n",
    "    return clean_dataset, removed_tickers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36ffe8f-1966-4a53-b030-5b53a8926115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_tech_data, removed_tickers = tech_clean(technical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50de7d70-e95f-4f46-9112-ffeeada84256",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-30 00:00:00-04:00</th>\n",
       "      <td>165.629147</td>\n",
       "      <td>165.939037</td>\n",
       "      <td>159.841418</td>\n",
       "      <td>159.886993</td>\n",
       "      <td>3235600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01 00:00:00-04:00</th>\n",
       "      <td>160.643498</td>\n",
       "      <td>161.700786</td>\n",
       "      <td>158.793250</td>\n",
       "      <td>161.035416</td>\n",
       "      <td>2419300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04 00:00:00-04:00</th>\n",
       "      <td>158.729428</td>\n",
       "      <td>161.418223</td>\n",
       "      <td>158.392195</td>\n",
       "      <td>160.452072</td>\n",
       "      <td>3010100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05 00:00:00-04:00</th>\n",
       "      <td>160.579685</td>\n",
       "      <td>162.794522</td>\n",
       "      <td>160.023713</td>\n",
       "      <td>162.129166</td>\n",
       "      <td>1888300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-06 00:00:00-04:00</th>\n",
       "      <td>160.989843</td>\n",
       "      <td>162.739830</td>\n",
       "      <td>159.978130</td>\n",
       "      <td>162.603104</td>\n",
       "      <td>2057600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2021-09-30 00:00:00-04:00  165.629147  165.939037  159.841418  159.886993   \n",
       "2021-10-01 00:00:00-04:00  160.643498  161.700786  158.793250  161.035416   \n",
       "2021-10-04 00:00:00-04:00  158.729428  161.418223  158.392195  160.452072   \n",
       "2021-10-05 00:00:00-04:00  160.579685  162.794522  160.023713  162.129166   \n",
       "2021-10-06 00:00:00-04:00  160.989843  162.739830  159.978130  162.603104   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits  \n",
       "Date                                                         \n",
       "2021-09-30 00:00:00-04:00  3235600        0.0           0.0  \n",
       "2021-10-01 00:00:00-04:00  2419300        0.0           0.0  \n",
       "2021-10-04 00:00:00-04:00  3010100        0.0           0.0  \n",
       "2021-10-05 00:00:00-04:00  1888300        0.0           0.0  \n",
       "2021-10-06 00:00:00-04:00  2057600        0.0           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tech_data['MMM'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f28c5a-336d-4563-a283-a0b63549ec27",
   "metadata": {},
   "source": [
    "### Get the train/testset for the LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81b62e-c7df-4a72-86cc-2b11af92264c",
   "metadata": {},
   "source": [
    "The train and testset for LSTM model will be in the follwing range of dates:\n",
    "2021-09-30 to 2023-06-30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d83127a-6f94-4272-8a79-77df11b26b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-09-30 00:00:00-0400', tz='America/New_York')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = pd.Timestamp('2021-09-30 00:00:00-0400', tz='America/New_York')\n",
    "end_date = pd.Timestamp('2023-06-30 00:00:00-0400', tz='America/New_York')\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeaf7ec9-4e60-42a3-875b-d3fbae492e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-30 00:00:00-04:00</th>\n",
       "      <td>165.629147</td>\n",
       "      <td>165.939037</td>\n",
       "      <td>159.841418</td>\n",
       "      <td>159.886993</td>\n",
       "      <td>3235600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01 00:00:00-04:00</th>\n",
       "      <td>160.643498</td>\n",
       "      <td>161.700786</td>\n",
       "      <td>158.793250</td>\n",
       "      <td>161.035416</td>\n",
       "      <td>2419300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-04 00:00:00-04:00</th>\n",
       "      <td>158.729428</td>\n",
       "      <td>161.418223</td>\n",
       "      <td>158.392195</td>\n",
       "      <td>160.452072</td>\n",
       "      <td>3010100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-05 00:00:00-04:00</th>\n",
       "      <td>160.579685</td>\n",
       "      <td>162.794522</td>\n",
       "      <td>160.023713</td>\n",
       "      <td>162.129166</td>\n",
       "      <td>1888300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-06 00:00:00-04:00</th>\n",
       "      <td>160.989843</td>\n",
       "      <td>162.739830</td>\n",
       "      <td>159.978130</td>\n",
       "      <td>162.603104</td>\n",
       "      <td>2057600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26 00:00:00-04:00</th>\n",
       "      <td>98.526526</td>\n",
       "      <td>99.403412</td>\n",
       "      <td>98.004337</td>\n",
       "      <td>98.930489</td>\n",
       "      <td>3655400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27 00:00:00-04:00</th>\n",
       "      <td>98.447701</td>\n",
       "      <td>98.743283</td>\n",
       "      <td>96.624962</td>\n",
       "      <td>96.812164</td>\n",
       "      <td>5429400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28 00:00:00-04:00</th>\n",
       "      <td>96.812170</td>\n",
       "      <td>97.807282</td>\n",
       "      <td>96.329384</td>\n",
       "      <td>97.117599</td>\n",
       "      <td>3795600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29 00:00:00-04:00</th>\n",
       "      <td>96.654523</td>\n",
       "      <td>97.994485</td>\n",
       "      <td>96.477175</td>\n",
       "      <td>97.777725</td>\n",
       "      <td>3496900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30 00:00:00-04:00</th>\n",
       "      <td>98.536381</td>\n",
       "      <td>98.920634</td>\n",
       "      <td>97.738311</td>\n",
       "      <td>98.615196</td>\n",
       "      <td>5085200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2021-09-30 00:00:00-04:00  165.629147  165.939037  159.841418  159.886993   \n",
       "2021-10-01 00:00:00-04:00  160.643498  161.700786  158.793250  161.035416   \n",
       "2021-10-04 00:00:00-04:00  158.729428  161.418223  158.392195  160.452072   \n",
       "2021-10-05 00:00:00-04:00  160.579685  162.794522  160.023713  162.129166   \n",
       "2021-10-06 00:00:00-04:00  160.989843  162.739830  159.978130  162.603104   \n",
       "...                               ...         ...         ...         ...   \n",
       "2023-06-26 00:00:00-04:00   98.526526   99.403412   98.004337   98.930489   \n",
       "2023-06-27 00:00:00-04:00   98.447701   98.743283   96.624962   96.812164   \n",
       "2023-06-28 00:00:00-04:00   96.812170   97.807282   96.329384   97.117599   \n",
       "2023-06-29 00:00:00-04:00   96.654523   97.994485   96.477175   97.777725   \n",
       "2023-06-30 00:00:00-04:00   98.536381   98.920634   97.738311   98.615196   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits  \n",
       "Date                                                         \n",
       "2021-09-30 00:00:00-04:00  3235600        0.0           0.0  \n",
       "2021-10-01 00:00:00-04:00  2419300        0.0           0.0  \n",
       "2021-10-04 00:00:00-04:00  3010100        0.0           0.0  \n",
       "2021-10-05 00:00:00-04:00  1888300        0.0           0.0  \n",
       "2021-10-06 00:00:00-04:00  2057600        0.0           0.0  \n",
       "...                            ...        ...           ...  \n",
       "2023-06-26 00:00:00-04:00  3655400        0.0           0.0  \n",
       "2023-06-27 00:00:00-04:00  5429400        0.0           0.0  \n",
       "2023-06-28 00:00:00-04:00  3795600        0.0           0.0  \n",
       "2023-06-29 00:00:00-04:00  3496900        0.0           0.0  \n",
       "2023-06-30 00:00:00-04:00  5085200        0.0           0.0  \n",
       "\n",
       "[440 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = clean_tech_data['MMM']\n",
    "\n",
    "test_df[(test_df.index >= start_date) & (test_df.index <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3654fac1-1df0-423b-ae1b-d13a48f57843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_test_subset(dict_technical_data, start_date, end_date):\n",
    "    \"\"\"\n",
    "    This function takes a dictionary of technical data as input and returns a dictionary \n",
    "    containing only the subset of technical data used in the train/test set.\n",
    "    \n",
    "    Parameters:\n",
    "    dict_fundamental_data : A dictionary where the key is the stock and the value is a \n",
    "    dataframe of the given stocks technical data.\n",
    "    \n",
    "    start_date: string in the format 'YYYY-MM-DD' and is start date of the train/test set\n",
    "    \n",
    "    end_date: string in the format 'YYYY-MM-DD' and is end date of the train/test set\n",
    "    \n",
    "    Returns:\n",
    "    dict_train_test: A dict where the key is the stock and the value is a df containing \n",
    "    only the dates between start_date and end_date\n",
    "    \"\"\"\n",
    "    # Convert the start and end date in pd.Timestamp format\n",
    "    start_date = pd.Timestamp(start_date + ' 00:00:00-0400', tz='America/New_York')\n",
    "    end_date = pd.Timestamp(end_date + ' 00:00:00-0400', tz='America/New_York')\n",
    "    \n",
    "    dict_train_test = {}\n",
    "    \n",
    "    for stock, data in dict_technical_data.items():\n",
    "        stock_df = data[(data.index >= start_date) & (data.index <= end_date)]\n",
    "        dict_train_test[stock] = stock_df\n",
    "    \n",
    "    return dict_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379d296f-043c-46be-87db-6c061ac21504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_train_test = get_train_test_subset(clean_tech_data, '2021-09-30', '2023-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68dc0fa-5984-4f4f-87e7-23c006ea7bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM 440\n",
      "AOS 440\n",
      "ABT 440\n",
      "ABBV 440\n",
      "ACN 440\n",
      "ATVI 440\n",
      "ADM 440\n",
      "ADBE 440\n",
      "ADP 440\n",
      "AAP 440\n",
      "AES 440\n",
      "AFL 440\n",
      "A 440\n",
      "APD 440\n",
      "AKAM 440\n",
      "ALK 440\n",
      "ALB 440\n",
      "ARE 440\n",
      "ALGN 440\n",
      "ALLE 440\n",
      "LNT 440\n",
      "ALL 440\n",
      "GOOGL 440\n",
      "GOOG 440\n",
      "MO 440\n",
      "AMZN 440\n",
      "AMCR 440\n",
      "AMD 440\n",
      "AEE 440\n",
      "AAL 440\n",
      "AEP 440\n",
      "AXP 440\n",
      "AIG 440\n",
      "AMT 440\n",
      "AWK 440\n",
      "AMP 440\n",
      "ABC 440\n",
      "AME 440\n",
      "AMGN 440\n",
      "APH 440\n",
      "ADI 440\n",
      "ANSS 440\n",
      "AON 440\n",
      "APA 440\n",
      "AAPL 440\n",
      "AMAT 440\n",
      "APTV 440\n",
      "ACGL 440\n",
      "ANET 440\n",
      "AJG 440\n",
      "AIZ 440\n",
      "T 440\n",
      "ATO 440\n",
      "ADSK 440\n",
      "AZO 440\n",
      "AVB 440\n",
      "AVY 440\n",
      "AXON 440\n",
      "BKR 440\n",
      "BALL 440\n",
      "BAC 440\n",
      "BBWI 440\n",
      "BAX 440\n",
      "BDX 440\n",
      "WRB 440\n",
      "BBY 440\n",
      "BIO 440\n",
      "TECH 440\n",
      "BIIB 440\n",
      "BLK 440\n",
      "BK 440\n",
      "BA 440\n",
      "BKNG 440\n",
      "BWA 440\n",
      "BXP 440\n",
      "BSX 440\n",
      "BMY 440\n",
      "AVGO 440\n",
      "BR 440\n",
      "BRO 440\n",
      "BG 440\n",
      "CHRW 440\n",
      "CDNS 440\n",
      "CZR 440\n",
      "CPT 440\n",
      "CPB 440\n",
      "COF 440\n",
      "CAH 440\n",
      "KMX 440\n",
      "CCL 440\n",
      "CARR 440\n",
      "CTLT 440\n",
      "CAT 440\n",
      "CBOE 440\n",
      "CBRE 440\n",
      "CDW 440\n",
      "CE 440\n",
      "CNC 440\n",
      "CNP 440\n",
      "CDAY 440\n",
      "CF 440\n",
      "CRL 440\n",
      "SCHW 440\n",
      "CHTR 440\n",
      "CVX 440\n",
      "CMG 440\n",
      "CB 440\n",
      "CHD 440\n",
      "CI 440\n",
      "CINF 440\n",
      "CTAS 440\n",
      "CSCO 440\n",
      "C 440\n",
      "CFG 440\n",
      "CLX 440\n",
      "CME 440\n",
      "CMS 440\n",
      "KO 440\n",
      "CTSH 440\n",
      "CL 440\n",
      "CMCSA 440\n",
      "CMA 440\n",
      "CAG 440\n",
      "COP 440\n",
      "ED 440\n",
      "STZ 440\n",
      "COO 440\n",
      "CPRT 440\n",
      "GLW 440\n",
      "CTVA 440\n",
      "CSGP 440\n",
      "COST 440\n",
      "CTRA 440\n",
      "CCI 440\n",
      "CSX 440\n",
      "CMI 440\n",
      "CVS 440\n",
      "DHI 440\n",
      "DHR 440\n",
      "DRI 440\n",
      "DVA 440\n",
      "DE 440\n",
      "DAL 440\n",
      "XRAY 440\n",
      "DVN 440\n",
      "DXCM 440\n",
      "FANG 440\n",
      "DLR 440\n",
      "DFS 440\n",
      "DISH 440\n",
      "DIS 440\n",
      "DG 440\n",
      "DLTR 440\n",
      "D 440\n",
      "DPZ 440\n",
      "DOV 440\n",
      "DOW 440\n",
      "DTE 440\n",
      "DUK 440\n",
      "DD 440\n",
      "DXC 440\n",
      "EMN 440\n",
      "ETN 440\n",
      "EBAY 440\n",
      "ECL 440\n",
      "EIX 440\n",
      "EW 440\n",
      "EA 440\n",
      "ELV 440\n",
      "LLY 440\n",
      "EMR 440\n",
      "ENPH 440\n",
      "ETR 440\n",
      "EOG 440\n",
      "EPAM 440\n",
      "EQT 440\n",
      "EFX 440\n",
      "EQIX 440\n",
      "EQR 440\n",
      "ESS 440\n",
      "EL 440\n",
      "ETSY 440\n",
      "EVRG 440\n",
      "ES 440\n",
      "EXC 440\n",
      "EXPE 440\n",
      "EXPD 440\n",
      "EXR 440\n",
      "XOM 440\n",
      "FFIV 440\n",
      "FDS 440\n",
      "FICO 440\n",
      "FAST 440\n",
      "FRT 440\n",
      "FDX 440\n",
      "FITB 440\n",
      "FSLR 440\n",
      "FE 440\n",
      "FIS 440\n",
      "FLT 440\n",
      "FMC 440\n",
      "F 440\n",
      "FTNT 440\n",
      "FTV 440\n",
      "FOXA 440\n",
      "FOX 440\n",
      "BEN 440\n",
      "FCX 440\n",
      "GRMN 440\n",
      "IT 440\n",
      "GEN 440\n",
      "GNRC 440\n",
      "GD 440\n",
      "GE 440\n",
      "GIS 440\n",
      "GM 440\n",
      "GPC 440\n",
      "GILD 440\n",
      "GL 440\n",
      "GPN 440\n",
      "GS 440\n",
      "HAL 440\n",
      "HIG 440\n",
      "HAS 440\n",
      "HCA 440\n",
      "PEAK 440\n",
      "HSIC 440\n",
      "HSY 440\n",
      "HES 440\n",
      "HPE 440\n",
      "HLT 440\n",
      "HOLX 440\n",
      "HD 440\n",
      "HON 440\n",
      "HRL 440\n",
      "HST 440\n",
      "HWM 440\n",
      "HPQ 440\n",
      "HUM 440\n",
      "HBAN 440\n",
      "HII 440\n",
      "IBM 440\n",
      "IEX 440\n",
      "IDXX 440\n",
      "ITW 440\n",
      "ILMN 440\n",
      "INCY 440\n",
      "IR 440\n",
      "PODD 440\n",
      "INTC 440\n",
      "ICE 440\n",
      "IFF 440\n",
      "IP 440\n",
      "IPG 440\n",
      "INTU 440\n",
      "ISRG 440\n",
      "IVZ 440\n",
      "INVH 440\n",
      "IQV 440\n",
      "IRM 440\n",
      "JBHT 440\n",
      "JKHY 440\n",
      "J 440\n",
      "JNJ 440\n",
      "JCI 440\n",
      "JPM 440\n",
      "JNPR 440\n",
      "K 440\n",
      "KDP 440\n",
      "KEY 440\n",
      "KEYS 440\n",
      "KMB 440\n",
      "KIM 440\n",
      "KMI 440\n",
      "KLAC 440\n",
      "KHC 440\n",
      "KR 440\n",
      "LHX 440\n",
      "LH 440\n",
      "LRCX 440\n",
      "LW 440\n",
      "LVS 440\n",
      "LDOS 440\n",
      "LEN 440\n",
      "LNC 440\n",
      "LIN 440\n",
      "LYV 440\n",
      "LKQ 440\n",
      "LMT 440\n",
      "L 440\n",
      "LOW 440\n",
      "LYB 440\n",
      "MTB 440\n",
      "MRO 440\n",
      "MPC 440\n",
      "MKTX 440\n",
      "MAR 440\n",
      "MMC 440\n",
      "MLM 440\n",
      "MAS 440\n",
      "MA 440\n",
      "MTCH 440\n",
      "MKC 440\n",
      "MCD 440\n",
      "MCK 440\n",
      "MDT 440\n",
      "MRK 440\n",
      "META 440\n",
      "MET 440\n",
      "MTD 440\n",
      "MGM 440\n",
      "MCHP 440\n",
      "MU 440\n",
      "MSFT 440\n",
      "MAA 440\n",
      "MRNA 440\n",
      "MHK 440\n",
      "MOH 440\n",
      "TAP 440\n",
      "MDLZ 440\n",
      "MPWR 440\n",
      "MNST 440\n",
      "MCO 440\n",
      "MS 440\n",
      "MOS 440\n",
      "MSI 440\n",
      "MSCI 440\n",
      "NDAQ 440\n",
      "NTAP 440\n",
      "NFLX 440\n",
      "NWL 440\n",
      "NEM 440\n",
      "NWSA 440\n",
      "NWS 440\n",
      "NEE 440\n",
      "NKE 440\n",
      "NI 440\n",
      "NDSN 440\n",
      "NSC 440\n",
      "NTRS 440\n",
      "NOC 440\n",
      "NCLH 440\n",
      "NRG 440\n",
      "NUE 440\n",
      "NVDA 440\n",
      "NVR 440\n",
      "NXPI 440\n",
      "ORLY 440\n",
      "OXY 440\n",
      "ODFL 440\n",
      "OMC 440\n",
      "ON 440\n",
      "OKE 440\n",
      "ORCL 440\n",
      "OGN 440\n",
      "OTIS 440\n",
      "PCAR 440\n",
      "PKG 440\n",
      "PARA 440\n",
      "PH 440\n",
      "PAYX 440\n",
      "PAYC 440\n",
      "PYPL 440\n",
      "PNR 440\n",
      "PEP 440\n",
      "PFE 440\n",
      "PCG 440\n",
      "PM 440\n",
      "PSX 440\n",
      "PNW 440\n",
      "PXD 440\n",
      "PNC 440\n",
      "POOL 440\n",
      "PPG 440\n",
      "PPL 440\n",
      "PFG 440\n",
      "PG 440\n",
      "PGR 440\n",
      "PLD 440\n",
      "PRU 440\n",
      "PEG 440\n",
      "PTC 440\n",
      "PSA 440\n",
      "PHM 440\n",
      "QRVO 440\n",
      "PWR 440\n",
      "QCOM 440\n",
      "DGX 440\n",
      "RL 440\n",
      "RJF 440\n",
      "RTX 440\n",
      "O 440\n",
      "REG 440\n",
      "REGN 440\n",
      "RF 440\n",
      "RSG 440\n",
      "RMD 440\n",
      "RHI 440\n",
      "ROK 440\n",
      "ROL 440\n",
      "ROP 440\n",
      "ROST 440\n",
      "RCL 440\n",
      "SPGI 440\n",
      "CRM 440\n",
      "SBAC 440\n",
      "SLB 440\n",
      "STX 440\n",
      "SEE 440\n",
      "SRE 440\n",
      "NOW 440\n",
      "SHW 440\n",
      "SPG 440\n",
      "SWKS 440\n",
      "SJM 440\n",
      "SNA 440\n",
      "SEDG 440\n",
      "SO 440\n",
      "LUV 440\n",
      "SWK 440\n",
      "SBUX 440\n",
      "STT 440\n",
      "STLD 440\n",
      "STE 440\n",
      "SYK 440\n",
      "SYF 440\n",
      "SNPS 440\n",
      "SYY 440\n",
      "TMUS 440\n",
      "TROW 440\n",
      "TTWO 440\n",
      "TPR 440\n",
      "TRGP 440\n",
      "TGT 440\n",
      "TEL 440\n",
      "TDY 440\n",
      "TFX 440\n",
      "TER 440\n",
      "TSLA 440\n",
      "TXN 440\n",
      "TXT 440\n",
      "TMO 440\n",
      "TJX 440\n",
      "TSCO 440\n",
      "TT 440\n",
      "TDG 440\n",
      "TRV 440\n",
      "TRMB 440\n",
      "TFC 440\n",
      "TYL 440\n",
      "TSN 440\n",
      "USB 440\n",
      "UDR 440\n",
      "ULTA 440\n",
      "UNP 440\n",
      "UAL 440\n",
      "UPS 440\n",
      "URI 440\n",
      "UNH 440\n",
      "UHS 440\n",
      "VLO 440\n",
      "VTR 440\n",
      "VRSN 440\n",
      "VRSK 440\n",
      "VZ 440\n",
      "VRTX 440\n",
      "VFC 440\n",
      "VTRS 440\n",
      "VICI 440\n",
      "V 440\n",
      "VMC 440\n",
      "WAB 440\n",
      "WBA 440\n",
      "WMT 440\n",
      "WBD 440\n",
      "WM 440\n",
      "WAT 440\n",
      "WEC 440\n",
      "WFC 440\n",
      "WELL 440\n",
      "WST 440\n",
      "WDC 440\n",
      "WRK 440\n",
      "WY 440\n",
      "WHR 440\n",
      "WMB 440\n",
      "WTW 440\n",
      "GWW 440\n",
      "WYNN 440\n",
      "XEL 440\n",
      "XYL 440\n",
      "YUM 440\n",
      "ZBRA 440\n",
      "ZBH 440\n",
      "ZION 440\n",
      "ZTS 440\n"
     ]
    }
   ],
   "source": [
    "for stock, data in dict_train_test.items():\n",
    "    print(stock,len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c9790-8eda-4163-a4ac-fcd867107714",
   "metadata": {},
   "source": [
    "### Get the LSTM model dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e09d6-f544-47e0-8ea0-3159766879c2",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c93a1672-617c-4af8-92e4-49bd541adce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_date_3_months_ahead(date_index):\n",
    "    \"\"\"\n",
    "    Takes a  pandas datetime index and pd dt 3 months ahead\n",
    "    \n",
    "    Parameters:\n",
    "    date_index:  pandas datetime indexes\n",
    "    \n",
    "    Returns:\n",
    "    array: Array of pandas datetime indexes 3 months ahead\n",
    "    \"\"\"\n",
    "    return date_index + pd.DateOffset(months=3)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'date_indexes' is an array of pandas datetime indexes\n",
    "# date_indexes = [...]  # Your array of pandas datetime indexes\n",
    "# result_dates = get_dates_3_months_ahead(date_indexes)\n",
    "# print(result_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb64ffdb-25a3-42ca-b269-b6a81f1469a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-30 00:00:00-04:00\n"
     ]
    }
   ],
   "source": [
    "def find_nearest_date(date_indexes, single_date):\n",
    "    \"\"\"\n",
    "    Finds the nearest date in the array of pandas datetime indexes to the given single datetime index.\n",
    "    \n",
    "    Parameters:\n",
    "    date_indexes (array-like): Array of pandas datetime indexes\n",
    "    single_date (pandas.Timestamp): Single pandas datetime index\n",
    "    \n",
    "    Returns:\n",
    "    pandas.Timestamp: Nearest datetime index in the array\n",
    "    \"\"\"\n",
    "    # Calculate absolute differences between single_date and each date in date_indexes\n",
    "    differences = abs(pd.Index(date_indexes) - single_date)\n",
    "    \n",
    "    # Find the index of the minimum difference\n",
    "    min_diff_index = differences.argmin()\n",
    "    \n",
    "    # Return the nearest date\n",
    "    return date_indexes[min_diff_index]\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'date_indexes' is an array of pandas datetime indexes\n",
    "# and 'single_date' is a single pandas datetime index\n",
    "nearest_date = find_nearest_date(clean_tech_data['MMM'].index, clean_tech_data['MMM'].index[0])\n",
    "print(nearest_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf94ae-9b61-402c-a882-78ca4c343723",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Split by stock df into 6 month chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3195971e-daaf-483e-aa45-ee7893fcb15c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1: Start Date: 2021-09-30 00:00:00-04:00, End Date: 2022-03-29 00:00:00-04:00\n",
      "Chunk 2: Start Date: 2022-03-31 00:00:00-04:00, End Date: 2022-09-29 00:00:00-04:00\n",
      "Chunk 3: Start Date: 2022-09-30 00:00:00-04:00, End Date: 2023-03-29 00:00:00-04:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def six_month_chunks(df):\n",
    "    dt_indx = df.index\n",
    "    # Resample the DataFrame with a 6-month frequency\n",
    "    chunks = df.resample('6M')\n",
    "\n",
    "    # Initialize lists to store start and end dates of chunks\n",
    "    start_dates = []\n",
    "    end_dates = []\n",
    "\n",
    "    # Iterate over the chunks\n",
    "    for start_date, chunk in chunks:\n",
    "        if (start_date + pd.DateOffset(months=6)) > dt_indx[-1]:\n",
    "            break\n",
    "        \n",
    "        start_dates.append(start_date)\n",
    "        end_date = start_date + pd.DateOffset(months=6) + pd.DateOffset(days=-1)\n",
    "        end_date = find_nearest_date(dt_indx, end_date)\n",
    "        end_dates.append(end_date)\n",
    "        #print(chunk)\n",
    "\n",
    "    return start_dates, end_dates\n",
    "\n",
    "# Call the function to get start and end dates of 6-month chunks\n",
    "start_dates, end_dates = six_month_chunks(dict_train_test['MMM'])\n",
    "\n",
    "# Print the results\n",
    "for i, (start, end) in enumerate(zip(start_dates, end_dates), 1):\n",
    "    print(f\"Chunk {i}: Start Date: {start}, End Date: {end}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556f28f-8c06-4afb-8da5-f059c7faee72",
   "metadata": {},
   "source": [
    "#### Create non-standardised dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fd7dcf8-88f6-46e9-b2cd-44a2abfb6601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_LSTM_data_single_stock(stock_df, start_dates, end_dates):\n",
    "    \"\"\"\n",
    "    This function creates LSTM dataset for each chunk \n",
    "    \n",
    "    Parameters:\n",
    "    stock_df (pandas dataframe): A pandas dataframe of the given stocks fundamnetal data\n",
    "    start_dates: A list of the start dates of every chunk \n",
    "    end_dates: A list of end dates for every chunk \n",
    "    \n",
    "    Returns:\n",
    "    single_stock_lst_X: List of Numpy arrays with 'Open','High','Low','Close' and 'Volume' as\n",
    "    x , datapoints as y and each element representing a seperate chunk.\n",
    "    single_stock_array_y: Array containing the following value for very chunk: \\\n",
    "    (The close price 3 months ahead of the last X sample in chunk / \\\n",
    "    The close price on last X sample in chunk)\n",
    "    \"\"\"\n",
    "    datetime_index = stock_df.index\n",
    "    single_stock_array_y = np.zeros(len(start_dates))\n",
    "    single_stock_lst_X = []\n",
    "    \n",
    "    \n",
    "    for chunk in range(len(start_dates)):\n",
    "        chunk_start = find_nearest_date(datetime_index, start_dates[chunk])\n",
    "        #print(chunk_start)\n",
    "        chunk_end = find_nearest_date(datetime_index, end_dates[chunk])\n",
    "        #print(chunk_end)\n",
    "        \n",
    "        chunk_df = stock_df[(stock_df.index >= chunk_start) & (stock_df.index <= chunk_end)]\n",
    "        X_arr = chunk_df[['Open','High','Low','Close','Volume']].to_numpy()\n",
    "        single_stock_lst_X.append(X_arr)\n",
    "        #print(X_arr.shape)\n",
    "        \n",
    "        price_final = stock_df.loc[end_date]['Close']\n",
    "        Y_date = get_date_3_months_ahead(chunk_end)\n",
    "        price_3mon = stock_df.loc[Y_date]['Close']\n",
    "        Y_chunk = price_3mon / price_final\n",
    "        single_stock_array_y[chunk] = Y_chunk\n",
    "    \n",
    "    return single_stock_lst_X, single_stock_array_y\n",
    "                       \n",
    "single_stock_lst_X, single_stock_array_y = create_LSTM_data_single_stock(dict_train_test['MMM'], start_dates, end_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50601f9a-24e7-404b-a6dc-5d9c69be38bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min sequence length is: 124\n",
      "The max sequence length is: 126\n"
     ]
    }
   ],
   "source": [
    "LSTM_non_standardised = {}\n",
    "min_seq_lens = []\n",
    "max_seq_lens = []\n",
    "for k, v in dict_train_test.items():\n",
    "    stock_data = create_LSTM_data_single_stock(v, start_dates, end_dates)\n",
    "    LSTM_non_standardised[k] = stock_data\n",
    "    \n",
    "    seq_lens = []\n",
    "    for chunk in stock_data[0]:\n",
    "        seq_lens.append(chunk.shape[0])\n",
    "    \n",
    "    min_seq_lens.append(min(seq_lens))\n",
    "    max_seq_lens.append(max(seq_lens))\n",
    "\n",
    "print(\"The min sequence length is:\", min(min_seq_lens))\n",
    "print(\"The max sequence length is:\", max(max_seq_lens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1618d7-0a69-41f4-8187-fdc9d36cc5b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "To make all sequnce lengths equal I will make them all length 124. Any sequence longer than 124 will have 1 or 2 of the first elements of the seqeunce removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c272e30-4f8f-4276-ad97-e6e6be4ef8e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create Standardised Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98e64ebc-e961-4d70-a478-90ee78de590f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc78c7b4-57e8-4351-85ea-a4d41ba097dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_LSTM_dataset(non_standardised_dataset, sequence_len):\n",
    "    \n",
    "    standardised_LSTM_data = {}\n",
    "    for stock, data in non_standardised_dataset.items():\n",
    "        X_data = data[0]\n",
    "        y_data = data[1]\n",
    "        \n",
    "        X_standardised_data = [standardise_seq(seq, sequence_len) for seq in X_data]\n",
    "        \n",
    "        standardised_LSTM_data[stock] = (X_standardised_data, y_data)\n",
    "    \n",
    "    return standardised_LSTM_data\n",
    "    \n",
    "        \n",
    "def standardise_seq(seq, sequence_len):\n",
    "    \n",
    "    standardised_len_seq = seq[-sequence_len:]\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(standardised_len_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "341564f3-ac85-4794-93f7-5299235281be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standardised_LSTM_data = standardise_LSTM_dataset(LSTM_non_standardised , min(min_seq_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ab03777-f98e-4f86-bffc-0cac33632619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/marcs/OneDrive/Documents/stock_analysis2/standardised_LSTM_data.pickle\", 'wb') as f:\n",
    "        pickle.dump(standardised_LSTM_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
